{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2hmENmZ0LrNs9vHlZWZsE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nofryntii/202055202008-Nofryanti/blob/master/Untitled22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "_GQbaiSDNXGA",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1ea1cbf-a525-41c0-970c-4a98535c0d39"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.12.0.88)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-contrib-python (from mediapipe)\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, sounddevice, opencv-contrib-python, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.12.0.88\n",
            "    Uninstalling opencv-contrib-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-contrib-python-4.12.0.88\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.21 numpy-1.26.4 opencv-contrib-python-4.11.0.86 protobuf-4.25.8 sounddevice-0.5.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "a162a6ed8a35444dbc88a6273f3ec847"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install mediapipe-model-maker"
      ],
      "metadata": {
        "id": "ZkdpuopONkKn",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad8aee4f-7cc9-46bc-a958-dc4c6aa8f0ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.1.1\n",
            "Collecting mediapipe-model-maker\n",
            "  Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (1.4.0)\n",
            "Requirement already satisfied: mediapipe>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (0.10.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (4.12.0.88)\n",
            "Collecting tensorflow<2.16,>=2.10 (from mediapipe-model-maker)\n",
            "  Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting tensorflow-addons (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (4.9.9)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (0.16.1)\n",
            "Collecting tensorflow-model-optimization<0.8.0 (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.11/dist-packages (from mediapipe-model-maker) (2.18.1)\n",
            "Collecting tf-models-official<2.16.0,>=2.13.2 (from mediapipe-model-maker)\n",
            "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.14.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (4.25.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (4.14.1)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.74.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2025.7.14)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.6.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization<0.8.0->mediapipe-model-maker) (0.1.9)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization<0.8.0->mediapipe-model-maker) (25.3.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.0.12)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (11.3.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.177.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.2.1)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.7.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.10.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.12.0.88)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.0.10)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.0.2)\n",
            "Collecting sacrebleu (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.2.0)\n",
            "Collecting seqeval (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-text (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.45.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.26.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (8.0.4)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.67.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.1)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.5.1)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (4.11.0.86)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.5.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.3.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (2.22)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub->mediapipe-model-maker) (2.18.0)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub->mediapipe-model-maker)\n",
            "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.0.2)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.7.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.6.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.6.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.6.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.4.8)\n",
            "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python (from mediapipe-model-maker)\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python-headless (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting portalocker (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.6.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->mediapipe-model-maker)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.7.2)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (1.13.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (18.1.0)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (1.17.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.10.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (3.23.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets->mediapipe-model-maker) (0.17.0)\n",
            "Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl (133 kB)\n",
            "Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "Downloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "Downloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax-0.4.34-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl (86.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.1/86.1 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: seqeval\n",
            "\u001b[33m  DEPRECATION: Building 'seqeval' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'seqeval'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=9cc006f3148e55c71e5680f6aae7f02a239daf37aa047fdaf9e3915560835787\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built seqeval\n",
            "Installing collected packages: wrapt, typeguard, tensorflow-estimator, portalocker, opencv-python-headless, opencv-python, ml-dtypes, keras, colorama, tensorflow-addons, sacrebleu, jaxlib, tensorflow-model-optimization, seqeval, jax, tensorboard, tensorflow, tf-keras, tensorflow-text, tf-models-official, mediapipe-model-maker\n",
            "\u001b[2K  Attempting uninstall: wrapt\n",
            "\u001b[2K    Found existing installation: wrapt 1.17.2\n",
            "\u001b[2K    Uninstalling wrapt-1.17.2:\n",
            "\u001b[2K      Successfully uninstalled wrapt-1.17.2\n",
            "\u001b[2K  Attempting uninstall: typeguard\n",
            "\u001b[2K    Found existing installation: typeguard 4.4.4\n",
            "\u001b[2K    Uninstalling typeguard-4.4.4:\n",
            "\u001b[2K      Successfully uninstalled typeguard-4.4.4\n",
            "\u001b[2K  Attempting uninstall: opencv-python-headless\n",
            "\u001b[2K    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "\u001b[2K    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "\u001b[2K      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "\u001b[2K  Attempting uninstall: opencv-python\n",
            "\u001b[2K    Found existing installation: opencv-python 4.12.0.88\n",
            "\u001b[2K    Uninstalling opencv-python-4.12.0.88:\n",
            "\u001b[2K      Successfully uninstalled opencv-python-4.12.0.88\n",
            "\u001b[2K  Attempting uninstall: ml-dtypes\n",
            "\u001b[2K    Found existing installation: ml-dtypes 0.4.1\n",
            "\u001b[2K    Uninstalling ml-dtypes-0.4.1:\n",
            "\u001b[2K      Successfully uninstalled ml-dtypes-0.4.1\n",
            "\u001b[2K  Attempting uninstall: keras\n",
            "\u001b[2K    Found existing installation: keras 3.8.0\n",
            "\u001b[2K    Uninstalling keras-3.8.0:\n",
            "\u001b[2K      Successfully uninstalled keras-3.8.0\n",
            "\u001b[2K  Attempting uninstall: jaxlib\n",
            "\u001b[2K    Found existing installation: jaxlib 0.5.1\n",
            "\u001b[2K    Uninstalling jaxlib-0.5.1:\n",
            "\u001b[2K      Successfully uninstalled jaxlib-0.5.1\n",
            "\u001b[2K  Attempting uninstall: jax\n",
            "\u001b[2K    Found existing installation: jax 0.5.2\n",
            "\u001b[2K    Uninstalling jax-0.5.2:\n",
            "\u001b[2K      Successfully uninstalled jax-0.5.2\n",
            "\u001b[2K  Attempting uninstall: tensorboard\n",
            "\u001b[2K    Found existing installation: tensorboard 2.18.0\n",
            "\u001b[2K    Uninstalling tensorboard-2.18.0:\n",
            "\u001b[2K      Successfully uninstalled tensorboard-2.18.0\n",
            "\u001b[2K  Attempting uninstall: tensorflow\n",
            "\u001b[2K    Found existing installation: tensorflow 2.18.0\n",
            "\u001b[2K    Uninstalling tensorflow-2.18.0:\n",
            "\u001b[2K      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[2K  Attempting uninstall: tf-keras\n",
            "\u001b[2K    Found existing installation: tf_keras 2.18.0\n",
            "\u001b[2K    Uninstalling tf_keras-2.18.0:\n",
            "\u001b[2K      Successfully uninstalled tf_keras-2.18.0\n",
            "\u001b[2K  Attempting uninstall: tensorflow-text\n",
            "\u001b[2K    Found existing installation: tensorflow-text 2.18.1\n",
            "\u001b[2K    Uninstalling tensorflow-text-2.18.1:\n",
            "\u001b[2K      Successfully uninstalled tensorflow-text-2.18.1\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/21\u001b[0m [mediapipe-model-maker]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.1 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tf-keras~=2.17, but you have tf-keras 2.15.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires tf-keras>=2.18.0, but you have tf-keras 2.15.1 which is incompatible.\n",
            "orbax-checkpoint 0.11.19 requires jax>=0.5.0, but you have jax 0.4.34 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.34 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 jax-0.4.34 jaxlib-0.4.34 keras-2.15.0 mediapipe-model-maker-0.2.1.4 ml-dtypes-0.3.2 opencv-python-4.11.0.86 opencv-python-headless-4.11.0.86 portalocker-3.2.0 sacrebleu-2.5.1 seqeval-1.2.2 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-addons-0.23.0 tensorflow-estimator-2.15.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tf-keras-2.15.1 tf-models-official-2.15.0 typeguard-2.13.3 wrapt-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "from mediapipe_model_maker.python.vision import gesture_recognizer\n",
        "from mediapipe.tasks.python.vision.gesture_recognizer import GestureRecognizer\n",
        "from mediapipe.framework.formats import landmark_pb2\n"
      ],
      "metadata": {
        "id": "4ngwxmXFMtw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030c7920-073d-4880-db33-eb8432024a68"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TbTfCL_rOLXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a47b6f83-2a33-4791-bbe7-66237545fd0e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root = pathlib.Path(\"/content/drive/MyDrive/bahasa\")"
      ],
      "metadata": {
        "id": "2UNyB0qcOT_t"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import utils"
      ],
      "metadata": {
        "id": "MJ8GP_mKOhuz"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan label dari dataset\n",
        "labels = [p.name for p in dataset_root.iterdir() if p.is_dir()]\n",
        "print(f\"Classes: {labels}\")\n",
        "\n",
        "# Mendapatkan daftar file gambar\n",
        "train_files = utils.find_images(dataset_root)\n",
        "print(f\"Number of training images: {len(train_files)}\")\n"
      ],
      "metadata": {
        "id": "lQmAxyg3O1R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d79764-6b04-457b-b06c-8510b2c9155f"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['A', 'none', 'Y', 'X', 'W', 'V', 'U', 'T', 'S', 'R', 'Q', 'P', 'O', 'N', 'M', 'L', 'K', 'I', 'H', 'G', 'F', 'E', 'D', 'C', 'B']\n",
            "Number of training images: 7340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_and_convert_images(dataset_path):\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img_path = os.path.join(root, file)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    # Konversi ke RGB\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    # Resize gambar ke ukuran yang diinginkan\n",
        "                    img = cv2.resize(img, (192, 192))\n",
        "                    # Simpan kembali\n",
        "                    cv2.imwrite(img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "# Jalankan fungsi konversi\n",
        "check_and_convert_images(dataset_root)"
      ],
      "metadata": {
        "id": "nLu6nN_RytJg"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def check_and_convert_images(dataset_path):\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img_path = os.path.join(root, file)\n",
        "\n",
        "                # Membaca gambar\n",
        "                img = cv2.imread(img_path)\n",
        "\n",
        "                if img is not None:\n",
        "                    # Cek jumlah channel gambar\n",
        "                    if len(img.shape) == 2:  # Jika gambar grayscale (1 channel)\n",
        "                        print(f\"Gambar grayscale terdeteksi: {img_path}\")\n",
        "                        # Konversi gambar grayscale menjadi RGB\n",
        "                        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "                    elif img.shape[2] == 3:  # Jika gambar berwarna (3 channel)\n",
        "                        # Konversi dari BGR ke RGB\n",
        "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                    # Resize gambar ke ukuran yang diinginkan\n",
        "                    img = cv2.resize(img, (192, 192))\n",
        "\n",
        "                    # Simpan kembali gambar dengan format BGR\n",
        "                    cv2.imwrite(img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "# Jalankan fungsi konversi\n",
        "dataset_root = \"/content/drive/MyDrive/bahasa\"\n",
        "check_and_convert_images(dataset_root)\n"
      ],
      "metadata": {
        "id": "y6fKVO6hqh9K"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_dataset_structure(dataset_path):\n",
        "    # Pastikan folder dataset ada\n",
        "    if not os.path.exists(dataset_path):\n",
        "        raise ValueError(f\"Dataset path {dataset_path} tidak ditemukan\")\n",
        "\n",
        "    # Variabel untuk menghitung total gambar\n",
        "    total_images = 0\n",
        "\n",
        "    # Hitung jumlah gambar per kelas\n",
        "    for class_name in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            n_images = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "            print(f\"Kelas {class_name}: {n_images} gambar\")\n",
        "            # Tambahkan jumlah gambar ke total\n",
        "            total_images += n_images\n",
        "\n",
        "    # Tampilkan total keseluruhan gambar\n",
        "    print(f\"\\nTotal keseluruhan gambar: {total_images} gambar\")\n",
        "\n",
        "# Menjalankan fungsi untuk memeriksa dataset\n",
        "verify_dataset_structure(dataset_root)\n"
      ],
      "metadata": {
        "id": "p5riBeKUt29u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb76bf0d-3309-49f5-b145-f9c437f01da3"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kelas A: 350 gambar\n",
            "Kelas none: 0 gambar\n",
            "Kelas Y: 317 gambar\n",
            "Kelas X: 344 gambar\n",
            "Kelas W: 287 gambar\n",
            "Kelas V: 291 gambar\n",
            "Kelas U: 310 gambar\n",
            "Kelas T: 301 gambar\n",
            "Kelas S: 298 gambar\n",
            "Kelas R: 290 gambar\n",
            "Kelas Q: 279 gambar\n",
            "Kelas P: 304 gambar\n",
            "Kelas O: 310 gambar\n",
            "Kelas N: 298 gambar\n",
            "Kelas M: 306 gambar\n",
            "Kelas L: 301 gambar\n",
            "Kelas K: 294 gambar\n",
            "Kelas I: 312 gambar\n",
            "Kelas H: 294 gambar\n",
            "Kelas G: 302 gambar\n",
            "Kelas F: 322 gambar\n",
            "Kelas E: 314 gambar\n",
            "Kelas D: 305 gambar\n",
            "Kelas C: 303 gambar\n",
            "Kelas B: 308 gambar\n",
            "\n",
            "Total keseluruhan gambar: 7340 gambar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import shutil\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def split_dataset(input_root, output_root, splits=\"80:20\", seed=None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    input_root = pathlib.Path(input_root)\n",
        "    output_root = pathlib.Path(output_root)\n",
        "\n",
        "    # Membagi persentase menjadi angka\n",
        "    split_percentages = [int(s) for s in splits.split(':')]\n",
        "\n",
        "    # Memastikan persentase berjumlah 100\n",
        "    assert sum(split_percentages) == 100, \"Total persentase harus 100\"\n",
        "\n",
        "    for labelpath in input_root.iterdir():\n",
        "        if not labelpath.is_dir():\n",
        "            continue\n",
        "\n",
        "        files = sorted(labelpath.iterdir())\n",
        "        np.random.shuffle(files)\n",
        "\n",
        "        # Hitung jumlah gambar untuk setiap split\n",
        "        total_files = len(files)\n",
        "        train_size = int(total_files * (split_percentages[0] / 100))\n",
        "        test_size = total_files - train_size\n",
        "\n",
        "        # Membagi dataset\n",
        "        subsets = {\n",
        "            'train': files[:train_size],\n",
        "            'test': files[train_size:]\n",
        "        }\n",
        "\n",
        "        # Menyimpan dataset ke folder output\n",
        "        for split_name, subset_files in subsets.items():\n",
        "            subset_root = output_root / split_name / labelpath.name\n",
        "            subset_root.mkdir(parents=True, exist_ok=True)\n",
        "            for file in subset_files:\n",
        "                shutil.copy(file, subset_root)\n",
        "\n",
        "        print(f\"Kelas {labelpath.name} - Train: {train_size}, Test: {test_size}\")\n",
        "\n",
        "# Menjalankan fungsi split dengan 80% untuk training dan 20% untuk testing\n",
        "output_root = \"/content/processed_data\"\n",
        "split_dataset(dataset_root, output_root, splits=\"70:30\", seed=42)\n"
      ],
      "metadata": {
        "id": "KLLqsG2XO6AY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a83ad8b-f1fc-4e0e-eaf4-d0db763bd422"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kelas A - Train: 244, Test: 106\n",
            "Kelas none - Train: 0, Test: 0\n",
            "Kelas Y - Train: 221, Test: 96\n",
            "Kelas X - Train: 240, Test: 104\n",
            "Kelas W - Train: 200, Test: 87\n",
            "Kelas V - Train: 203, Test: 88\n",
            "Kelas U - Train: 217, Test: 93\n",
            "Kelas T - Train: 210, Test: 91\n",
            "Kelas S - Train: 208, Test: 90\n",
            "Kelas R - Train: 203, Test: 87\n",
            "Kelas Q - Train: 195, Test: 84\n",
            "Kelas P - Train: 212, Test: 92\n",
            "Kelas O - Train: 217, Test: 93\n",
            "Kelas N - Train: 208, Test: 90\n",
            "Kelas M - Train: 214, Test: 92\n",
            "Kelas L - Train: 210, Test: 91\n",
            "Kelas K - Train: 205, Test: 89\n",
            "Kelas I - Train: 218, Test: 94\n",
            "Kelas H - Train: 205, Test: 89\n",
            "Kelas G - Train: 211, Test: 91\n",
            "Kelas F - Train: 225, Test: 97\n",
            "Kelas E - Train: 219, Test: 95\n",
            "Kelas D - Train: 213, Test: 92\n",
            "Kelas C - Train: 212, Test: 91\n",
            "Kelas B - Train: 215, Test: 93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = gesture_recognizer.Dataset.from_folder(str(dataset_root))\n",
        "train_data.gen_tf_dataset().unbatch().save(\"/content/train_data\")"
      ],
      "metadata": {
        "id": "pxMsTp7-RecP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2135035e-c625-4e13-cf6d-1341cbf5c06b"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/gesture_embedder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_root = pathlib.Path(\"/content/processed_data\")"
      ],
      "metadata": {
        "id": "DJQ5WNiCZO7l"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "\n",
        "import utils\n",
        "\n",
        "data_root = pathlib.Path(\"./processed_data\")\n",
        "dataset_train = data_root / \"train\"\n",
        "trainfiles = utils.find_images(dataset_train)\n",
        "\n",
        "sample_files = np.random.choice(np.asarray(trainfiles), 10)\n",
        "fig, axarr = utils.plot_image_files(sample_files, ncols=5)\n",
        "fig.savefig(\"example-output.jpg\", dpi=150, bbox_inches=\"tight\")"
      ],
      "metadata": {
        "id": "aDwaujag63qo"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VFHzSQFh62tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mediapipe_model_maker.python.vision import gesture_recognizer\n",
        "\n",
        "handparams = gesture_recognizer.HandDataPreprocessingParams(\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "dataset_train = data_root / \"train\"\n",
        "data = gesture_recognizer.Dataset.from_folder(str(dataset_train), handparams)\n",
        "train_data, validation_data = data.split(0.8)\n",
        "\n",
        "dataset_test = data_root / \"test\"\n",
        "test_data = gesture_recognizer.Dataset.from_folder(\n",
        "    str(dataset_test), handparams\n",
        ")\n"
      ],
      "metadata": {
        "id": "XeTn3-RoUo_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ef6d8df-ef2e-4a97-cf01-2049fdf633b3"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/gesture_embedder\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/gesture_embedder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainfiles = utils.find_images(dataset_train)\n",
        "\n",
        "sample_files = np.random.choice(np.asarray(trainfiles), 10)\n",
        "fig, axarr = utils.plot_image_files(sample_files, ncols=5)\n",
        "fig.savefig(\"outputdataset.jpg\", dpi=150, bbox_inches=\"tight\")"
      ],
      "metadata": {
        "id": "qTqpjm80WrNo"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = gesture_recognizer.HParams(\n",
        "    export_dir=\"exported_model\",\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    shuffle=True,\n",
        "    learning_rate=0.001,\n",
        "    lr_decay=0.95,\n",
        ")\n",
        "moptions = gesture_recognizer.ModelOptions(dropout_rate=0.05)\n",
        "options = gesture_recognizer.GestureRecognizerOptions(\n",
        "    hparams=hparams, model_options=moptions\n",
        ")\n",
        "\n",
        "model = gesture_recognizer.GestureRecognizer.create(\n",
        "    train_data=train_data, validation_data=validation_data, options=options\n",
        ")\n"
      ],
      "metadata": {
        "id": "2bS8AvXcWdMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46ae77e-8747-454e-cafb-a69b1d3d0697"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hand_embedding (InputLayer  [(None, 128)]             0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " custom_gesture_recognizer_  (None, 25)                3225      \n",
            " out (Dense)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3737 (14.60 KB)\n",
            "Trainable params: 3481 (13.60 KB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Resuming from exported_model/epoch_models/model-0100\n",
            "Epoch 1/100\n",
            "166/166 [==============================] - 8s 38ms/step - loss: 0.1390 - categorical_accuracy: 0.9264 - val_loss: 0.1133 - val_categorical_accuracy: 0.9467 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "166/166 [==============================] - 11s 66ms/step - loss: 0.1320 - categorical_accuracy: 0.9264 - val_loss: 0.1148 - val_categorical_accuracy: 0.9474 - lr: 9.5000e-04\n",
            "Epoch 3/100\n",
            "166/166 [==============================] - 6s 36ms/step - loss: 0.1340 - categorical_accuracy: 0.9260 - val_loss: 0.1140 - val_categorical_accuracy: 0.9437 - lr: 9.0250e-04\n",
            "Epoch 4/100\n",
            "166/166 [==============================] - 8s 50ms/step - loss: 0.1234 - categorical_accuracy: 0.9298 - val_loss: 0.1158 - val_categorical_accuracy: 0.9452 - lr: 8.5737e-04\n",
            "Epoch 5/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1217 - categorical_accuracy: 0.9313 - val_loss: 0.1156 - val_categorical_accuracy: 0.9459 - lr: 8.1451e-04\n",
            "Epoch 6/100\n",
            "166/166 [==============================] - 6s 36ms/step - loss: 0.1220 - categorical_accuracy: 0.9294 - val_loss: 0.1178 - val_categorical_accuracy: 0.9421 - lr: 7.7378e-04\n",
            "Epoch 7/100\n",
            "166/166 [==============================] - 8s 49ms/step - loss: 0.1257 - categorical_accuracy: 0.9262 - val_loss: 0.1168 - val_categorical_accuracy: 0.9459 - lr: 7.3509e-04\n",
            "Epoch 8/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1269 - categorical_accuracy: 0.9294 - val_loss: 0.1186 - val_categorical_accuracy: 0.9444 - lr: 6.9834e-04\n",
            "Epoch 9/100\n",
            "166/166 [==============================] - 8s 50ms/step - loss: 0.1147 - categorical_accuracy: 0.9328 - val_loss: 0.1173 - val_categorical_accuracy: 0.9459 - lr: 6.6342e-04\n",
            "Epoch 10/100\n",
            "166/166 [==============================] - 8s 50ms/step - loss: 0.1192 - categorical_accuracy: 0.9283 - val_loss: 0.1175 - val_categorical_accuracy: 0.9444 - lr: 6.3025e-04\n",
            "Epoch 11/100\n",
            "166/166 [==============================] - 6s 36ms/step - loss: 0.1173 - categorical_accuracy: 0.9264 - val_loss: 0.1193 - val_categorical_accuracy: 0.9444 - lr: 5.9874e-04\n",
            "Epoch 12/100\n",
            "166/166 [==============================] - 8s 50ms/step - loss: 0.1188 - categorical_accuracy: 0.9339 - val_loss: 0.1187 - val_categorical_accuracy: 0.9444 - lr: 5.6880e-04\n",
            "Epoch 13/100\n",
            "166/166 [==============================] - 6s 36ms/step - loss: 0.1185 - categorical_accuracy: 0.9311 - val_loss: 0.1187 - val_categorical_accuracy: 0.9459 - lr: 5.4036e-04\n",
            "Epoch 14/100\n",
            "166/166 [==============================] - 7s 38ms/step - loss: 0.1169 - categorical_accuracy: 0.9302 - val_loss: 0.1191 - val_categorical_accuracy: 0.9437 - lr: 5.1334e-04\n",
            "Epoch 15/100\n",
            "166/166 [==============================] - 9s 51ms/step - loss: 0.1096 - categorical_accuracy: 0.9356 - val_loss: 0.1195 - val_categorical_accuracy: 0.9444 - lr: 4.8767e-04\n",
            "Epoch 16/100\n",
            "166/166 [==============================] - 6s 36ms/step - loss: 0.1154 - categorical_accuracy: 0.9303 - val_loss: 0.1192 - val_categorical_accuracy: 0.9429 - lr: 4.6329e-04\n",
            "Epoch 17/100\n",
            "166/166 [==============================] - 8s 50ms/step - loss: 0.1157 - categorical_accuracy: 0.9341 - val_loss: 0.1196 - val_categorical_accuracy: 0.9444 - lr: 4.4013e-04\n",
            "Epoch 18/100\n",
            "166/166 [==============================] - 7s 42ms/step - loss: 0.1143 - categorical_accuracy: 0.9305 - val_loss: 0.1190 - val_categorical_accuracy: 0.9444 - lr: 4.1812e-04\n",
            "Epoch 19/100\n",
            "166/166 [==============================] - 6s 36ms/step - loss: 0.1124 - categorical_accuracy: 0.9322 - val_loss: 0.1192 - val_categorical_accuracy: 0.9467 - lr: 3.9721e-04\n",
            "Epoch 20/100\n",
            "166/166 [==============================] - 8s 49ms/step - loss: 0.1106 - categorical_accuracy: 0.9362 - val_loss: 0.1194 - val_categorical_accuracy: 0.9452 - lr: 3.7735e-04\n",
            "Epoch 21/100\n",
            "166/166 [==============================] - 6s 36ms/step - loss: 0.1099 - categorical_accuracy: 0.9352 - val_loss: 0.1200 - val_categorical_accuracy: 0.9444 - lr: 3.5849e-04\n",
            "Epoch 22/100\n",
            "166/166 [==============================] - 8s 50ms/step - loss: 0.1095 - categorical_accuracy: 0.9322 - val_loss: 0.1185 - val_categorical_accuracy: 0.9459 - lr: 3.4056e-04\n",
            "Epoch 23/100\n",
            "166/166 [==============================] - 6s 36ms/step - loss: 0.1143 - categorical_accuracy: 0.9296 - val_loss: 0.1196 - val_categorical_accuracy: 0.9437 - lr: 3.2353e-04\n",
            "Epoch 24/100\n",
            "166/166 [==============================] - 8s 46ms/step - loss: 0.1173 - categorical_accuracy: 0.9300 - val_loss: 0.1203 - val_categorical_accuracy: 0.9437 - lr: 3.0736e-04\n",
            "Epoch 25/100\n",
            "166/166 [==============================] - 14s 82ms/step - loss: 0.1118 - categorical_accuracy: 0.9341 - val_loss: 0.1203 - val_categorical_accuracy: 0.9452 - lr: 2.9199e-04\n",
            "Epoch 26/100\n",
            "166/166 [==============================] - 9s 51ms/step - loss: 0.1110 - categorical_accuracy: 0.9330 - val_loss: 0.1211 - val_categorical_accuracy: 0.9444 - lr: 2.7739e-04\n",
            "Epoch 27/100\n",
            "166/166 [==============================] - 7s 42ms/step - loss: 0.1101 - categorical_accuracy: 0.9337 - val_loss: 0.1211 - val_categorical_accuracy: 0.9429 - lr: 2.6352e-04\n",
            "Epoch 28/100\n",
            "166/166 [==============================] - 7s 43ms/step - loss: 0.1120 - categorical_accuracy: 0.9313 - val_loss: 0.1215 - val_categorical_accuracy: 0.9414 - lr: 2.5034e-04\n",
            "Epoch 29/100\n",
            "166/166 [==============================] - 8s 50ms/step - loss: 0.1093 - categorical_accuracy: 0.9351 - val_loss: 0.1206 - val_categorical_accuracy: 0.9459 - lr: 2.3783e-04\n",
            "Epoch 30/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1113 - categorical_accuracy: 0.9315 - val_loss: 0.1204 - val_categorical_accuracy: 0.9459 - lr: 2.2594e-04\n",
            "Epoch 31/100\n",
            "166/166 [==============================] - 9s 51ms/step - loss: 0.1064 - categorical_accuracy: 0.9351 - val_loss: 0.1203 - val_categorical_accuracy: 0.9459 - lr: 2.1464e-04\n",
            "Epoch 32/100\n",
            "166/166 [==============================] - 6s 38ms/step - loss: 0.1147 - categorical_accuracy: 0.9364 - val_loss: 0.1210 - val_categorical_accuracy: 0.9452 - lr: 2.0391e-04\n",
            "Epoch 33/100\n",
            "166/166 [==============================] - 8s 49ms/step - loss: 0.1065 - categorical_accuracy: 0.9379 - val_loss: 0.1207 - val_categorical_accuracy: 0.9452 - lr: 1.9371e-04\n",
            "Epoch 34/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1077 - categorical_accuracy: 0.9356 - val_loss: 0.1208 - val_categorical_accuracy: 0.9437 - lr: 1.8403e-04\n",
            "Epoch 35/100\n",
            "166/166 [==============================] - 7s 38ms/step - loss: 0.1080 - categorical_accuracy: 0.9341 - val_loss: 0.1211 - val_categorical_accuracy: 0.9444 - lr: 1.7482e-04\n",
            "Epoch 36/100\n",
            "166/166 [==============================] - 7s 43ms/step - loss: 0.1078 - categorical_accuracy: 0.9334 - val_loss: 0.1209 - val_categorical_accuracy: 0.9459 - lr: 1.6608e-04\n",
            "Epoch 37/100\n",
            "166/166 [==============================] - 8s 44ms/step - loss: 0.1041 - categorical_accuracy: 0.9356 - val_loss: 0.1211 - val_categorical_accuracy: 0.9467 - lr: 1.5778e-04\n",
            "Epoch 38/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1061 - categorical_accuracy: 0.9381 - val_loss: 0.1211 - val_categorical_accuracy: 0.9467 - lr: 1.4989e-04\n",
            "Epoch 39/100\n",
            "166/166 [==============================] - 7s 41ms/step - loss: 0.1110 - categorical_accuracy: 0.9335 - val_loss: 0.1207 - val_categorical_accuracy: 0.9452 - lr: 1.4240e-04\n",
            "Epoch 40/100\n",
            "166/166 [==============================] - 9s 50ms/step - loss: 0.1076 - categorical_accuracy: 0.9388 - val_loss: 0.1205 - val_categorical_accuracy: 0.9459 - lr: 1.3528e-04\n",
            "Epoch 41/100\n",
            "166/166 [==============================] - 8s 45ms/step - loss: 0.1108 - categorical_accuracy: 0.9337 - val_loss: 0.1206 - val_categorical_accuracy: 0.9467 - lr: 1.2851e-04\n",
            "Epoch 42/100\n",
            "166/166 [==============================] - 6s 38ms/step - loss: 0.1091 - categorical_accuracy: 0.9366 - val_loss: 0.1208 - val_categorical_accuracy: 0.9459 - lr: 1.2209e-04\n",
            "Epoch 43/100\n",
            "166/166 [==============================] - 7s 43ms/step - loss: 0.1064 - categorical_accuracy: 0.9334 - val_loss: 0.1206 - val_categorical_accuracy: 0.9467 - lr: 1.1598e-04\n",
            "Epoch 44/100\n",
            "166/166 [==============================] - 9s 51ms/step - loss: 0.1060 - categorical_accuracy: 0.9319 - val_loss: 0.1209 - val_categorical_accuracy: 0.9467 - lr: 1.1018e-04\n",
            "Epoch 45/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1061 - categorical_accuracy: 0.9347 - val_loss: 0.1206 - val_categorical_accuracy: 0.9459 - lr: 1.0467e-04\n",
            "Epoch 46/100\n",
            "166/166 [==============================] - 9s 52ms/step - loss: 0.1073 - categorical_accuracy: 0.9322 - val_loss: 0.1204 - val_categorical_accuracy: 0.9459 - lr: 9.9440e-05\n",
            "Epoch 47/100\n",
            "166/166 [==============================] - 8s 50ms/step - loss: 0.1037 - categorical_accuracy: 0.9339 - val_loss: 0.1207 - val_categorical_accuracy: 0.9459 - lr: 9.4468e-05\n",
            "Epoch 48/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1040 - categorical_accuracy: 0.9366 - val_loss: 0.1206 - val_categorical_accuracy: 0.9459 - lr: 8.9745e-05\n",
            "Epoch 49/100\n",
            "166/166 [==============================] - 8s 47ms/step - loss: 0.1094 - categorical_accuracy: 0.9334 - val_loss: 0.1208 - val_categorical_accuracy: 0.9459 - lr: 8.5258e-05\n",
            "Epoch 50/100\n",
            "166/166 [==============================] - 8s 50ms/step - loss: 0.1056 - categorical_accuracy: 0.9360 - val_loss: 0.1210 - val_categorical_accuracy: 0.9459 - lr: 8.0995e-05\n",
            "Epoch 51/100\n",
            "166/166 [==============================] - 7s 38ms/step - loss: 0.1017 - categorical_accuracy: 0.9360 - val_loss: 0.1214 - val_categorical_accuracy: 0.9459 - lr: 7.6945e-05\n",
            "Epoch 52/100\n",
            "166/166 [==============================] - 9s 53ms/step - loss: 0.1045 - categorical_accuracy: 0.9366 - val_loss: 0.1210 - val_categorical_accuracy: 0.9467 - lr: 7.3098e-05\n",
            "Epoch 53/100\n",
            "166/166 [==============================] - 8s 48ms/step - loss: 0.1034 - categorical_accuracy: 0.9354 - val_loss: 0.1209 - val_categorical_accuracy: 0.9459 - lr: 6.9443e-05\n",
            "Epoch 54/100\n",
            "166/166 [==============================] - 12s 69ms/step - loss: 0.1040 - categorical_accuracy: 0.9362 - val_loss: 0.1208 - val_categorical_accuracy: 0.9467 - lr: 6.5971e-05\n",
            "Epoch 55/100\n",
            "166/166 [==============================] - 11s 65ms/step - loss: 0.1034 - categorical_accuracy: 0.9373 - val_loss: 0.1212 - val_categorical_accuracy: 0.9459 - lr: 6.2672e-05\n",
            "Epoch 56/100\n",
            "166/166 [==============================] - 12s 70ms/step - loss: 0.1069 - categorical_accuracy: 0.9337 - val_loss: 0.1211 - val_categorical_accuracy: 0.9467 - lr: 5.9539e-05\n",
            "Epoch 57/100\n",
            "166/166 [==============================] - 9s 50ms/step - loss: 0.1064 - categorical_accuracy: 0.9339 - val_loss: 0.1214 - val_categorical_accuracy: 0.9467 - lr: 5.6562e-05\n",
            "Epoch 58/100\n",
            "166/166 [==============================] - 12s 70ms/step - loss: 0.1041 - categorical_accuracy: 0.9352 - val_loss: 0.1212 - val_categorical_accuracy: 0.9467 - lr: 5.3734e-05\n",
            "Epoch 59/100\n",
            "166/166 [==============================] - 8s 48ms/step - loss: 0.1045 - categorical_accuracy: 0.9339 - val_loss: 0.1214 - val_categorical_accuracy: 0.9474 - lr: 5.1047e-05\n",
            "Epoch 60/100\n",
            "166/166 [==============================] - 10s 60ms/step - loss: 0.1094 - categorical_accuracy: 0.9335 - val_loss: 0.1214 - val_categorical_accuracy: 0.9474 - lr: 4.8495e-05\n",
            "Epoch 61/100\n",
            "166/166 [==============================] - 8s 48ms/step - loss: 0.1036 - categorical_accuracy: 0.9328 - val_loss: 0.1215 - val_categorical_accuracy: 0.9474 - lr: 4.6070e-05\n",
            "Epoch 62/100\n",
            "166/166 [==============================] - 13s 77ms/step - loss: 0.1068 - categorical_accuracy: 0.9360 - val_loss: 0.1216 - val_categorical_accuracy: 0.9474 - lr: 4.3766e-05\n",
            "Epoch 63/100\n",
            "166/166 [==============================] - 11s 66ms/step - loss: 0.1063 - categorical_accuracy: 0.9349 - val_loss: 0.1215 - val_categorical_accuracy: 0.9459 - lr: 4.1578e-05\n",
            "Epoch 64/100\n",
            "166/166 [==============================] - 9s 50ms/step - loss: 0.1079 - categorical_accuracy: 0.9352 - val_loss: 0.1213 - val_categorical_accuracy: 0.9452 - lr: 3.9499e-05\n",
            "Epoch 65/100\n",
            "166/166 [==============================] - 10s 57ms/step - loss: 0.1095 - categorical_accuracy: 0.9366 - val_loss: 0.1214 - val_categorical_accuracy: 0.9467 - lr: 3.7524e-05\n",
            "Epoch 66/100\n",
            "166/166 [==============================] - 11s 64ms/step - loss: 0.1028 - categorical_accuracy: 0.9375 - val_loss: 0.1214 - val_categorical_accuracy: 0.9474 - lr: 3.5648e-05\n",
            "Epoch 67/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1033 - categorical_accuracy: 0.9379 - val_loss: 0.1213 - val_categorical_accuracy: 0.9467 - lr: 3.3866e-05\n",
            "Epoch 68/100\n",
            "166/166 [==============================] - 8s 46ms/step - loss: 0.1073 - categorical_accuracy: 0.9332 - val_loss: 0.1214 - val_categorical_accuracy: 0.9459 - lr: 3.2172e-05\n",
            "Epoch 69/100\n",
            "166/166 [==============================] - 9s 51ms/step - loss: 0.1052 - categorical_accuracy: 0.9332 - val_loss: 0.1215 - val_categorical_accuracy: 0.9467 - lr: 3.0564e-05\n",
            "Epoch 70/100\n",
            "166/166 [==============================] - 6s 36ms/step - loss: 0.1073 - categorical_accuracy: 0.9356 - val_loss: 0.1212 - val_categorical_accuracy: 0.9467 - lr: 2.9035e-05\n",
            "Epoch 71/100\n",
            "166/166 [==============================] - 7s 41ms/step - loss: 0.1024 - categorical_accuracy: 0.9362 - val_loss: 0.1211 - val_categorical_accuracy: 0.9474 - lr: 2.7584e-05\n",
            "Epoch 72/100\n",
            "166/166 [==============================] - 8s 45ms/step - loss: 0.1039 - categorical_accuracy: 0.9341 - val_loss: 0.1213 - val_categorical_accuracy: 0.9467 - lr: 2.6205e-05\n",
            "Epoch 73/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1035 - categorical_accuracy: 0.9351 - val_loss: 0.1213 - val_categorical_accuracy: 0.9467 - lr: 2.4894e-05\n",
            "Epoch 74/100\n",
            "166/166 [==============================] - 7s 39ms/step - loss: 0.0991 - categorical_accuracy: 0.9367 - val_loss: 0.1213 - val_categorical_accuracy: 0.9467 - lr: 2.3650e-05\n",
            "Epoch 75/100\n",
            "166/166 [==============================] - 9s 51ms/step - loss: 0.1091 - categorical_accuracy: 0.9341 - val_loss: 0.1212 - val_categorical_accuracy: 0.9467 - lr: 2.2467e-05\n",
            "Epoch 76/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1041 - categorical_accuracy: 0.9373 - val_loss: 0.1214 - val_categorical_accuracy: 0.9474 - lr: 2.1344e-05\n",
            "Epoch 77/100\n",
            "166/166 [==============================] - 7s 40ms/step - loss: 0.1025 - categorical_accuracy: 0.9360 - val_loss: 0.1213 - val_categorical_accuracy: 0.9467 - lr: 2.0277e-05\n",
            "Epoch 78/100\n",
            "166/166 [==============================] - 9s 51ms/step - loss: 0.1044 - categorical_accuracy: 0.9351 - val_loss: 0.1214 - val_categorical_accuracy: 0.9459 - lr: 1.9263e-05\n",
            "Epoch 79/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1081 - categorical_accuracy: 0.9339 - val_loss: 0.1214 - val_categorical_accuracy: 0.9467 - lr: 1.8300e-05\n",
            "Epoch 80/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1070 - categorical_accuracy: 0.9352 - val_loss: 0.1214 - val_categorical_accuracy: 0.9467 - lr: 1.7385e-05\n",
            "Epoch 81/100\n",
            "166/166 [==============================] - 9s 52ms/step - loss: 0.1056 - categorical_accuracy: 0.9322 - val_loss: 0.1212 - val_categorical_accuracy: 0.9459 - lr: 1.6515e-05\n",
            "Epoch 82/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1008 - categorical_accuracy: 0.9369 - val_loss: 0.1213 - val_categorical_accuracy: 0.9467 - lr: 1.5690e-05\n",
            "Epoch 83/100\n",
            "166/166 [==============================] - 11s 64ms/step - loss: 0.1055 - categorical_accuracy: 0.9339 - val_loss: 0.1214 - val_categorical_accuracy: 0.9467 - lr: 1.4905e-05\n",
            "Epoch 84/100\n",
            "166/166 [==============================] - 6s 36ms/step - loss: 0.1089 - categorical_accuracy: 0.9383 - val_loss: 0.1214 - val_categorical_accuracy: 0.9467 - lr: 1.4160e-05\n",
            "Epoch 85/100\n",
            "166/166 [==============================] - 7s 39ms/step - loss: 0.1055 - categorical_accuracy: 0.9367 - val_loss: 0.1213 - val_categorical_accuracy: 0.9459 - lr: 1.3452e-05\n",
            "Epoch 86/100\n",
            "166/166 [==============================] - 8s 45ms/step - loss: 0.1022 - categorical_accuracy: 0.9371 - val_loss: 0.1213 - val_categorical_accuracy: 0.9459 - lr: 1.2779e-05\n",
            "Epoch 87/100\n",
            "166/166 [==============================] - 7s 41ms/step - loss: 0.1065 - categorical_accuracy: 0.9334 - val_loss: 0.1213 - val_categorical_accuracy: 0.9459 - lr: 1.2140e-05\n",
            "Epoch 88/100\n",
            "166/166 [==============================] - 9s 50ms/step - loss: 0.0999 - categorical_accuracy: 0.9356 - val_loss: 0.1213 - val_categorical_accuracy: 0.9459 - lr: 1.1533e-05\n",
            "Epoch 89/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1127 - categorical_accuracy: 0.9339 - val_loss: 0.1213 - val_categorical_accuracy: 0.9459 - lr: 1.0957e-05\n",
            "Epoch 90/100\n",
            "166/166 [==============================] - 8s 50ms/step - loss: 0.1079 - categorical_accuracy: 0.9364 - val_loss: 0.1212 - val_categorical_accuracy: 0.9459 - lr: 1.0409e-05\n",
            "Epoch 91/100\n",
            "166/166 [==============================] - 6s 36ms/step - loss: 0.1035 - categorical_accuracy: 0.9379 - val_loss: 0.1213 - val_categorical_accuracy: 0.9459 - lr: 9.8884e-06\n",
            "Epoch 92/100\n",
            "166/166 [==============================] - 8s 50ms/step - loss: 0.1009 - categorical_accuracy: 0.9383 - val_loss: 0.1212 - val_categorical_accuracy: 0.9459 - lr: 9.3939e-06\n",
            "Epoch 93/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1018 - categorical_accuracy: 0.9341 - val_loss: 0.1212 - val_categorical_accuracy: 0.9459 - lr: 8.9242e-06\n",
            "Epoch 94/100\n",
            "166/166 [==============================] - 6s 38ms/step - loss: 0.1053 - categorical_accuracy: 0.9337 - val_loss: 0.1213 - val_categorical_accuracy: 0.9459 - lr: 8.4780e-06\n",
            "Epoch 95/100\n",
            "166/166 [==============================] - 7s 43ms/step - loss: 0.1033 - categorical_accuracy: 0.9335 - val_loss: 0.1212 - val_categorical_accuracy: 0.9459 - lr: 8.0541e-06\n",
            "Epoch 96/100\n",
            "166/166 [==============================] - 9s 54ms/step - loss: 0.1099 - categorical_accuracy: 0.9332 - val_loss: 0.1214 - val_categorical_accuracy: 0.9467 - lr: 7.6514e-06\n",
            "Epoch 97/100\n",
            "166/166 [==============================] - 6s 37ms/step - loss: 0.1062 - categorical_accuracy: 0.9347 - val_loss: 0.1215 - val_categorical_accuracy: 0.9459 - lr: 7.2689e-06\n",
            "Epoch 98/100\n",
            "166/166 [==============================] - 7s 37ms/step - loss: 0.1070 - categorical_accuracy: 0.9315 - val_loss: 0.1213 - val_categorical_accuracy: 0.9459 - lr: 6.9054e-06\n",
            "Epoch 99/100\n",
            "166/166 [==============================] - 9s 52ms/step - loss: 0.1032 - categorical_accuracy: 0.9341 - val_loss: 0.1214 - val_categorical_accuracy: 0.9459 - lr: 6.5601e-06\n",
            "Epoch 100/100\n",
            "166/166 [==============================] - 9s 51ms/step - loss: 0.1063 - categorical_accuracy: 0.9358 - val_loss: 0.1214 - val_categorical_accuracy: 0.9459 - lr: 6.2321e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_data, batch_size=1)\n",
        "print(f\"Test loss: {loss:.4f}, Test accuracy: {acc:.2%}\")"
      ],
      "metadata": {
        "id": "0V6OCj8JSMmj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de48adb4-0edc-42ce-fe39-8de6e2375932"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3603/3603 [==============================] - 9s 2ms/step - loss: 0.0885 - categorical_accuracy: 0.9548\n",
            "Test loss: 0.0885, Test accuracy: 95.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.export_model(\"model.task\")"
      ],
      "metadata": {
        "id": "kmcb1tQxcI28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b75e0d9-1159-4aeb-af55-5f763a414e93"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing files at /tmp/model_maker/gesture_recognizer/gesture_embedder.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/canned_gesture_classifier.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root = pathlib.Path(\"/content/processed_data/test\")\n",
        "testfiles = list(dataset_root.glob(\"**/*.jpg\"))  # Semua file JPG dalam dataset"
      ],
      "metadata": {
        "id": "sEQ3X2BygS9-"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = np.random.choice(testfiles)"
      ],
      "metadata": {
        "id": "wWF1geOlg1UW"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(testfiles), testfiles[:10])  # Periksa jumlah dan contoh file gambar"
      ],
      "metadata": {
        "id": "vbAHQLBIhZDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a28a17-325e-4a52-e14d-664b02182089"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3967 [PosixPath('/content/processed_data/test/K/K87 dtf.jpg'), PosixPath('/content/processed_data/test/K/K213 dtf.jpg'), PosixPath('/content/processed_data/test/K/K148 dtf.jpg'), PosixPath('/content/processed_data/test/K/K153 dtf.jpg'), PosixPath('/content/processed_data/test/K/K74 dtf.jpg'), PosixPath('/content/processed_data/test/K/K25 dtf.jpg'), PosixPath('/content/processed_data/test/K/K79 dtf.jpg'), PosixPath('/content/processed_data/test/K/K257 dtf.jpg'), PosixPath('/content/processed_data/test/K/K130 dtf.jpg'), PosixPath('/content/processed_data/test/K/K216 dtf.jpg')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "from mediapipe.tasks.python.vision.gesture_recognizer import GestureRecognizer\n",
        "\n",
        "base_options = mp.tasks.BaseOptions(\n",
        "    model_asset_path=hparams.export_dir + \"/model.task\"\n",
        ")\n",
        "options = mp.tasks.vision.GestureRecognizerOptions(\n",
        "    base_options=base_options, running_mode=mp.tasks.vision.RunningMode.IMAGE\n",
        ")\n",
        "\n",
        "with GestureRecognizer.create_from_options(options) as recognizer:\n",
        "    mp_image = mp.Image.create_from_file(str(filename))\n",
        "    result = recognizer.recognize(mp_image)\n"
      ],
      "metadata": {
        "id": "B_D6wKF6c6_a"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = np.random.choice(np.asarray(testfiles), 10)\n",
        "\n",
        "with GestureRecognizer.create_from_options(options) as recognizer:\n",
        "    fig, axarr = utils.plot_recognizer_predictions(test_samples, recognizer, 5)\n",
        "fig.savefig(\"example-output.jpg\", dpi=150, bbox_inches=\"tight\")"
      ],
      "metadata": {
        "id": "7Pyn-8jmg6RU"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "AwvZHSufhBPF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1788c62a-2729-4025-8553-9fad7a9d1ff9"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm  # Tambahkan ini jika belum ada\n",
        "\n",
        "test_results = []\n",
        "with mp.tasks.vision.GestureRecognizer.create_from_options(options) as recognizer:\n",
        "    for filename in tqdm(testfiles, desc=\"Processing test files\"):\n",
        "        mp_image = mp.Image.create_from_file(str(filename))\n",
        "        result = recognizer.recognize(mp_image)\n",
        "        if len(result.gestures) > 0:\n",
        "            pred = result.gestures[0][0].category_name or \"n/a\"\n",
        "        else:\n",
        "            pred = \"empty\"\n",
        "        test_results.append((filename, filename.parent.name, pred))\n",
        "\n",
        "# Convert to DataFrame\n",
        "results_df = pd.DataFrame(test_results, columns=[\"filename\", \"label\", \"pred\"])\n"
      ],
      "metadata": {
        "id": "nSaBkNo1c_p3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26ff1f9-4cd7-4310-b76e-6681e5aec598"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing test files: 100%|██████████| 3967/3967 [04:05<00:00, 16.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "# Menentukan urutan kelas\n",
        "classes = sorted(test_data.label_names + [\"n/a\", \"empty\"])\n",
        "\n",
        "# Menghitung confusion matrix tanpa normalisasi\n",
        "cm = sklearn.metrics.confusion_matrix(\n",
        "    results_df[\"label\"], results_df[\"pred\"], labels=classes\n",
        ")\n",
        "\n",
        "# Membuat objek ConfusionMatrixDisplay\n",
        "disp = sklearn.metrics.ConfusionMatrixDisplay(cm, display_labels=classes)\n",
        "\n",
        "# Membuat figure dan axis\n",
        "fig, ax = plt.subplots()  # Menyesuaikan ukuran untuk visualisasi lebih baik\n",
        "\n",
        "# Plot confusion matrix tanpa grid\n",
        "disp.plot(include_values=False, cmap=\"Blues\", ax=ax)\n",
        "ax.grid(False)\n",
        "ax.set_facecolor(\"white\")\n",
        "\n",
        "# Menambahkan nilai pada sel, hanya jika tidak nol, dengan warna abu-abu\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        if cm[i, j] != 0:  # Menampilkan nilai hanya jika bukan nol\n",
        "            ax.text(\n",
        "                j, i, f\"{cm[i, j]}\",\n",
        "                ha=\"center\", va=\"center\", color=\"gold\", fontsize=8\n",
        "            )\n",
        "\n",
        "# Menyimpan plot ke file dan menampilkannya\n",
        "plt.savefig(\"confusion_matrix_filtered_gray_text.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ILAKMIpRbzNm"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "\n",
        "# Menambahkan kolom 'result' untuk mengevaluasi apakah prediksi benar atau salah\n",
        "results_df[\"result\"] = results_df[\"pred\"] == results_df[\"label\"]\n",
        "\n",
        "# Menghitung precision, recall, dan f1-score untuk masing-masing kelas\n",
        "report = classification_report(\n",
        "    results_df[\"label\"],\n",
        "    results_df[\"pred\"],\n",
        "    labels=results_df[\"label\"].unique(),  # Memastikan semua label muncul di laporan\n",
        "    zero_division=0\n",
        ")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "Zt9Sa1hhOsTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb27a61-0efd-47de-bfc6-0a5f6ac15718"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           K       0.99      0.81      0.89       158\n",
            "           B       0.98      0.92      0.95       309\n",
            "           U       0.92      0.82      0.87       159\n",
            "           F       0.99      0.84      0.91       167\n",
            "           T       0.89      0.87      0.88       155\n",
            "           M       0.99      0.86      0.92       159\n",
            "           O       0.97      0.84      0.90       161\n",
            "           W       1.00      0.82      0.90       156\n",
            "           D       0.93      0.82      0.87       152\n",
            "           R       0.92      0.75      0.83       149\n",
            "           P       0.99      0.83      0.90       162\n",
            "           G       0.99      0.81      0.89       162\n",
            "           X       0.99      0.77      0.86       179\n",
            "           I       0.96      0.92      0.94       161\n",
            "           E       0.99      0.92      0.95       167\n",
            "           C       0.98      0.86      0.92       150\n",
            "           H       1.00      0.84      0.91       153\n",
            "           V       0.97      0.84      0.90       162\n",
            "           S       0.95      0.86      0.90       160\n",
            "           N       0.97      0.88      0.92       157\n",
            "           Q       0.96      0.80      0.87       152\n",
            "           L       1.00      0.88      0.94       153\n",
            "           A       0.99      0.96      0.97       161\n",
            "           Y       1.00      0.88      0.93       163\n",
            "\n",
            "   micro avg       0.97      0.85      0.91      3967\n",
            "   macro avg       0.97      0.85      0.91      3967\n",
            "weighted avg       0.97      0.85      0.91      3967\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import mediapipe as mp\n",
        "\n",
        "test_results = []\n",
        "\n",
        "# Asumsikan 'options' sudah dibuat sebelumnya\n",
        "with mp.tasks.vision.GestureRecognizer.create_from_options(options) as recognizer:\n",
        "    for filename in tqdm(testfiles, desc=\"Processing test files\"):\n",
        "        mp_image = mp.Image.create_from_file(str(filename))\n",
        "        result = recognizer.recognize(mp_image)\n",
        "\n",
        "        if len(result.gestures) > 0:\n",
        "            gesture = result.gestures[0][0]\n",
        "            pred = gesture.category_name or \"n/a\"\n",
        "            score = gesture.score\n",
        "        else:\n",
        "            pred = \"empty\"\n",
        "            score = 0.0\n",
        "\n",
        "        test_results.append((filename.name, filename.parent.name, pred, score))\n",
        "\n",
        "# Buat DataFrame\n",
        "results_df = pd.DataFrame(test_results, columns=[\"file\", \"label\", \"pred\", \"confidence\"])\n",
        "\n",
        "# Tambahkan kolom 'result'\n",
        "results_df[\"result\"] = results_df[\"pred\"] == results_df[\"label\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4tQyKila0Dt",
        "outputId": "6604477f-d397-4982-f886-2789965b771b"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing test files: 100%|██████████| 3967/3967 [03:51<00:00, 17.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LIAT DATA AKURASI RENDAH\n",
        "from tabulate import tabulate\n",
        "\n",
        "low_conf_df = results_df[results_df[\"confidence\"] < 0.50]\n",
        "\n",
        "print(\"\\n🔍 Gambar dengan prediksi confidence di bawah 50%:\\n\")\n",
        "print(tabulate(\n",
        "    low_conf_df[[\"file\", \"label\", \"pred\", \"confidence\", \"result\"]],\n",
        "    headers=\"keys\",\n",
        "    tablefmt=\"pretty\",\n",
        "    floatfmt=\".2f\"\n",
        "))\n"
      ],
      "metadata": {
        "id": "oaMnMzVsQ6x_",
        "outputId": "fdd91639-8415-486a-d8ee-860187af82c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Gambar dengan prediksi confidence di bawah 50%:\n",
            "\n",
            "+------+--------------+-------+-------+------------+--------+\n",
            "|      |     file     | label | pred  | confidence | result |\n",
            "+------+--------------+-------+-------+------------+--------+\n",
            "|  0   | K213 dtf.jpg |   K   | empty |    0.0     | False  |\n",
            "|  14  | K196 dtf.jpg |   K   | empty |    0.0     | False  |\n",
            "|  17  | K134 dtf.jpg |   K   | empty |    0.0     | False  |\n",
            "|  30  | K166 dtf.jpg |   K   | empty |    0.0     | False  |\n",
            "|  44  | K299 dtf.jpg |   K   | empty |    0.0     | False  |\n",
            "|  52  | K154 dtf.jpg |   K   | empty |    0.0     | False  |\n",
            "|  57  | K139 dtf.jpg |   K   | empty |    0.0     | False  |\n",
            "|  64  | K158 dtf.jpg |   K   | empty |    0.0     | False  |\n",
            "|  87  | K62 dtf.jpg  |   K   | empty |    0.0     | False  |\n",
            "|  88  | K165 dtf.jpg |   K   | empty |    0.0     | False  |\n",
            "| 100  | B347 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 115  | B556 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 171  | B346 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 226  | B351 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 227  | B223 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 230  | B327 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 236  | B545 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 248  | B227 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 266  | B483 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 282  | B566 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 294  | B444 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 329  | B321 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 332  | B563 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 341  | B440 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 351  | B564 dtf.jpg |   B   | empty |    0.0     | False  |\n",
            "| 382  | U106 dtf.jpg |   U   | empty |    0.0     | False  |\n",
            "| 403  | U264 dtf.jpg |   U   | empty |    0.0     | False  |\n",
            "| 412  | U261 dtf.jpg |   U   | empty |    0.0     | False  |\n",
            "| 419  | U267 dtf.jpg |   U   | empty |    0.0     | False  |\n",
            "| 426  | U113 dtf.jpg |   U   | empty |    0.0     | False  |\n",
            "| 429  | U194 dtf.jpg |   U   | empty |    0.0     | False  |\n",
            "| 453  | F181 dtf.jpg |   F   | empty |    0.0     | False  |\n",
            "| 463  | F307 dtf.jpg |   F   | empty |    0.0     | False  |\n",
            "| 470  | F175 dtf.jpg |   F   | empty |    0.0     | False  |\n",
            "| 495  | F169 dtf.jpg |   F   | empty |    0.0     | False  |\n",
            "| 501  | F300 dtf.jpg |   F   | empty |    0.0     | False  |\n",
            "| 502  | F168 dtf.jpg |   F   | empty |    0.0     | False  |\n",
            "| 531  | F301 dtf.jpg |   F   | empty |    0.0     | False  |\n",
            "| 535  | F182 dtf.jpg |   F   | empty |    0.0     | False  |\n",
            "| 634  | T280 dtf.jpg |   T   | empty |    0.0     | False  |\n",
            "| 647  | M176 dtf.jpg |   M   | empty |    0.0     | False  |\n",
            "| 662  | M47 dtf.jpg  |   M   | empty |    0.0     | False  |\n",
            "| 716  | M175 dtf.jpg |   M   | empty |    0.0     | False  |\n",
            "| 718  | M190 dtf.jpg |   M   | empty |    0.0     | False  |\n",
            "| 725  | M48 dtf.jpg  |   M   | empty |    0.0     | False  |\n",
            "| 832  | W31 dtf.jpg  |   W   | empty |    0.0     | False  |\n",
            "| 836  | W296 dtf.jpg |   W   | empty |    0.0     | False  |\n",
            "| 846  | W174 dtf.jpg |   W   | empty |    0.0     | False  |\n",
            "| 857  | W79 dtf.jpg  |   W   | empty |    0.0     | False  |\n",
            "| 861  | W288 dtf.jpg |   W   | empty |    0.0     | False  |\n",
            "| 869  | W290 dtf.jpg |   W   | empty |    0.0     | False  |\n",
            "| 872  | W56 dtf.jpg  |   W   | empty |    0.0     | False  |\n",
            "| 873  | W140 dtf.jpg |   W   | empty |    0.0     | False  |\n",
            "| 880  | W181 dtf.jpg |   W   | empty |    0.0     | False  |\n",
            "| 886  | W155 dtf.jpg |   W   | empty |    0.0     | False  |\n",
            "| 891  | W295 dtf.jpg |   W   | empty |    0.0     | False  |\n",
            "| 899  | W38 dtf.jpg  |   W   | empty |    0.0     | False  |\n",
            "| 906  | W166 dtf.jpg |   W   | empty |    0.0     | False  |\n",
            "| 909  | W160 dtf.jpg |   W   | empty |    0.0     | False  |\n",
            "| 910  | W148 dtf.jpg |   W   | empty |    0.0     | False  |\n",
            "| 914  | W55 dtf.jpg  |   W   | empty |    0.0     | False  |\n",
            "| 915  | W291 dtf.jpg |   W   | empty |    0.0     | False  |\n",
            "| 928  | D52 dtf.jpg  |   D   | empty |    0.0     | False  |\n",
            "| 937  | D110 dtf.jpg |   D   | empty |    0.0     | False  |\n",
            "| 989  | D87 dtf.jpg  |   D   | empty |    0.0     | False  |\n",
            "| 1009 | D237 dtf.jpg |   D   | empty |    0.0     | False  |\n",
            "| 1017 | R34 dtf.jpg  |   R   | empty |    0.0     | False  |\n",
            "| 1023 | R167 dtf.jpg |   R   | empty |    0.0     | False  |\n",
            "| 1026 | R101 dtf.jpg |   R   | empty |    0.0     | False  |\n",
            "| 1027 | R162 dtf.jpg |   R   | empty |    0.0     | False  |\n",
            "| 1039 | R172 dtf.jpg |   R   | empty |    0.0     | False  |\n",
            "| 1044 | R76 dtf.jpg  |   R   | empty |    0.0     | False  |\n",
            "| 1060 | R289 dtf.jpg |   R   | empty |    0.0     | False  |\n",
            "| 1067 | R176 dtf.jpg |   R   | empty |    0.0     | False  |\n",
            "| 1080 | R51 dtf.jpg  |   R   | empty |    0.0     | False  |\n",
            "| 1083 | R202 dtf.jpg |   R   | empty |    0.0     | False  |\n",
            "| 1088 | R293 dtf.jpg |   R   | empty |    0.0     | False  |\n",
            "| 1119 | P28 dtf.jpg  |   P   | empty |    0.0     | False  |\n",
            "| 1124 | P18 dtf.jpg  |   P   | empty |    0.0     | False  |\n",
            "| 1125 | P31 dtf.jpg  |   P   | empty |    0.0     | False  |\n",
            "| 1151 | P29 dtf.jpg  |   P   | empty |    0.0     | False  |\n",
            "| 1155 | P24 dtf.jpg  |   P   | empty |    0.0     | False  |\n",
            "| 1157 | P21 dtf.jpg  |   P   | empty |    0.0     | False  |\n",
            "| 1168 | P95 dtf.jpg  |   P   | empty |    0.0     | False  |\n",
            "| 1175 |  P7 dtf.jpg  |   P   | empty |    0.0     | False  |\n",
            "| 1176 | P33 dtf.jpg  |   P   | empty |    0.0     | False  |\n",
            "| 1177 | P223 dtf.jpg |   P   | empty |    0.0     | False  |\n",
            "| 1182 | P112 dtf.jpg |   P   | empty |    0.0     | False  |\n",
            "| 1187 | P217 dtf.jpg |   P   | empty |    0.0     | False  |\n",
            "| 1195 | P63 dtf.jpg  |   P   | empty |    0.0     | False  |\n",
            "| 1205 | G174 dtf.jpg |   G   | empty |    0.0     | False  |\n",
            "| 1207 | G306 dtf.jpg |   G   | empty |    0.0     | False  |\n",
            "| 1217 | G69 dtf.jpg  |   G   | empty |    0.0     | False  |\n",
            "| 1220 | G178 dtf.jpg |   G   | empty |    0.0     | False  |\n",
            "| 1227 | G171 dtf.jpg |   G   | empty |    0.0     | False  |\n",
            "| 1238 | G166 dtf.jpg |   G   | empty |    0.0     | False  |\n",
            "| 1239 | G313 dtf.jpg |   G   | empty |    0.0     | False  |\n",
            "| 1250 | G177 dtf.jpg |   G   | empty |    0.0     | False  |\n",
            "| 1262 | G173 dtf.jpg |   G   | empty |    0.0     | False  |\n",
            "| 1269 | G179 dtf.jpg |   G   | empty |    0.0     | False  |\n",
            "| 1274 | G70 dtf.jpg  |   G   | empty |    0.0     | False  |\n",
            "| 1302 | X181 dtf.jpg |   X   | empty |    0.0     | False  |\n",
            "| 1306 | X230 dtf.jpg |   X   | empty |    0.0     | False  |\n",
            "| 1308 | X208 dtf.jpg |   X   | empty |    0.0     | False  |\n",
            "| 1310 | X211 dtf.jpg |   X   | empty |    0.0     | False  |\n",
            "| 1314 | X204 dtf.jpg |   X   | empty |    0.0     | False  |\n",
            "| 1317 | X238 dtf.jpg |   X   | empty |    0.0     | False  |\n",
            "| 1327 | X356 dtf.jpg |   X   | empty |    0.0     | False  |\n",
            "| 1342 | X353 dtf.jpg |   X   | empty |    0.0     | False  |\n",
            "| 1349 | X65 dtf.jpg  |   X   | empty |    0.0     | False  |\n",
            "| 1357 | X153 dtf.jpg |   X   | empty |    0.0     | False  |\n",
            "| 1374 | X205 dtf.jpg |   X   | empty |    0.0     | False  |\n",
            "| 1378 | X194 dtf.jpg |   X   | empty |    0.0     | False  |\n",
            "| 1384 | X222 dtf.jpg |   X   | empty |    0.0     | False  |\n",
            "| 1399 | X199 dtf.jpg |   X   | empty |    0.0     | False  |\n",
            "| 1409 | I185 dtf.jpg |   I   | empty |    0.0     | False  |\n",
            "| 1418 | I187 dtf.jpg |   I   | empty |    0.0     | False  |\n",
            "| 1440 | I302 dtf.jpg |   I   | empty |    0.0     | False  |\n",
            "| 1450 | I173 dtf.jpg |   I   | empty |    0.0     | False  |\n",
            "| 1461 | I183 dtf.jpg |   I   | empty |    0.0     | False  |\n",
            "| 1488 | I188 dtf.jpg |   I   | empty |    0.0     | False  |\n",
            "| 1501 | E191 dtf.jpg |   E   | empty |    0.0     | False  |\n",
            "| 1509 | E189 dtf.jpg |   E   | empty |    0.0     | False  |\n",
            "| 1533 | E192 dtf.jpg |   E   | empty |    0.0     | False  |\n",
            "| 1550 | E188 dtf.jpg |   E   | empty |    0.0     | False  |\n",
            "| 1552 | E201 dtf.jpg |   E   | empty |    0.0     | False  |\n",
            "| 1572 | E297 dtf.jpg |   E   | empty |    0.0     | False  |\n",
            "| 1596 | C105 dtf.jpg |   C   | empty |    0.0     | False  |\n",
            "| 1609 | C53 dtf.jpg  |   C   | empty |    0.0     | False  |\n",
            "| 1611 | C52 dtf.jpg  |   C   | empty |    0.0     | False  |\n",
            "| 1632 | C88 dtf.jpg  |   C   | empty |    0.0     | False  |\n",
            "| 1646 | C80 dtf.jpg  |   C   | empty |    0.0     | False  |\n",
            "| 1665 |  C2 dtf.jpg  |   C   | empty |    0.0     | False  |\n",
            "| 1673 | C15 dtf.jpg  |   C   | empty |    0.0     | False  |\n",
            "| 1683 | C66 dtf.jpg  |   C   | empty |    0.0     | False  |\n",
            "| 1692 | H298 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1693 | H78 dtf.jpg  |   H   | empty |    0.0     | False  |\n",
            "| 1696 | H308 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1700 | H47 dtf.jpg  |   H   | empty |    0.0     | False  |\n",
            "| 1704 | H309 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1710 | H173 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1714 | H175 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1716 | H182 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1718 | H194 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1726 | H165 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1727 | H177 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1730 | H185 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1734 | H208 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1737 | H169 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1739 | H205 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1743 | H301 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1773 | H167 dtf.jpg |   H   | empty |    0.0     | False  |\n",
            "| 1786 | V154 dtf.jpg |   V   | empty |    0.0     | False  |\n",
            "| 1790 | V277 dtf.jpg |   V   | empty |    0.0     | False  |\n",
            "| 1792 | V176 dtf.jpg |   V   | empty |    0.0     | False  |\n",
            "| 1804 | V131 dtf.jpg |   V   | empty |    0.0     | False  |\n",
            "| 1812 | V179 dtf.jpg |   V   | empty |    0.0     | False  |\n",
            "| 1827 | V172 dtf.jpg |   V   | empty |    0.0     | False  |\n",
            "| 1833 | V174 dtf.jpg |   V   | empty |    0.0     | False  |\n",
            "| 1858 | V64 dtf.jpg  |   V   | empty |    0.0     | False  |\n",
            "| 1865 | V171 dtf.jpg |   V   | empty |    0.0     | False  |\n",
            "| 1871 | V191 dtf.jpg |   V   | empty |    0.0     | False  |\n",
            "| 1879 | S179 dtf.jpg |   S   | empty |    0.0     | False  |\n",
            "| 1889 | S160 dtf.jpg |   S   | empty |    0.0     | False  |\n",
            "| 1890 | S177 dtf.jpg |   S   | empty |    0.0     | False  |\n",
            "| 1905 | S175 dtf.jpg |   S   | empty |    0.0     | False  |\n",
            "| 1907 | S276 dtf.jpg |   S   | empty |    0.0     | False  |\n",
            "| 1922 | S275 dtf.jpg |   S   | empty |    0.0     | False  |\n",
            "| 1936 | S283 dtf.jpg |   S   | empty |    0.0     | False  |\n",
            "| 1962 | S176 dtf.jpg |   S   | empty |    0.0     | False  |\n",
            "| 1964 | S182 dtf.jpg |   S   | empty |    0.0     | False  |\n",
            "| 1965 | S180 dtf.jpg |   S   | empty |    0.0     | False  |\n",
            "| 1975 | N173 dtf.jpg |   N   | empty |    0.0     | False  |\n",
            "| 1988 | N102 dtf.jpg |   N   | empty |    0.0     | False  |\n",
            "| 1990 | N170 dtf.jpg |   N   | empty |    0.0     | False  |\n",
            "| 2001 | N288 dtf.jpg |   N   | empty |    0.0     | False  |\n",
            "| 2011 | N174 dtf.jpg |   N   | empty |    0.0     | False  |\n",
            "| 2025 | N167 dtf.jpg |   N   | empty |    0.0     | False  |\n",
            "| 2039 | N171 dtf.jpg |   N   | empty |    0.0     | False  |\n",
            "| 2043 | N169 dtf.jpg |   N   | empty |    0.0     | False  |\n",
            "| 2059 | Q17 dtf.jpg  |   Q   | empty |    0.0     | False  |\n",
            "| 2067 | Q184 dtf.jpg |   Q   | empty |    0.0     | False  |\n",
            "| 2076 |  Q6 dtf.jpg  |   Q   | empty |    0.0     | False  |\n",
            "| 2087 | Q44 dtf.jpg  |   Q   | empty |    0.0     | False  |\n",
            "| 2098 | Q18 dtf.jpg  |   Q   | empty |    0.0     | False  |\n",
            "| 2109 | Q174 dtf.jpg |   Q   | empty |    0.0     | False  |\n",
            "| 2110 | Q34 dtf.jpg  |   Q   | empty |    0.0     | False  |\n",
            "| 2113 | Q50 dtf.jpg  |   Q   | empty |    0.0     | False  |\n",
            "| 2125 | Q15 dtf.jpg  |   Q   | empty |    0.0     | False  |\n",
            "| 2129 | Q61 dtf.jpg  |   Q   | empty |    0.0     | False  |\n",
            "| 2144 |  Q4 dtf.jpg  |   Q   | empty |    0.0     | False  |\n",
            "| 2145 | Q60 dtf.jpg  |   Q   | empty |    0.0     | False  |\n",
            "| 2146 | L31 dtf.jpg  |   L   | empty |    0.0     | False  |\n",
            "| 2173 | L164 dtf.jpg |   L   | empty |    0.0     | False  |\n",
            "| 2176 | L172 dtf.jpg |   L   | empty |    0.0     | False  |\n",
            "| 2214 | L159 dtf.jpg |   L   | empty |    0.0     | False  |\n",
            "| 2218 | L33 dtf.jpg  |   L   | empty |    0.0     | False  |\n",
            "| 2223 | L173 dtf.jpg |   L   | empty |    0.0     | False  |\n",
            "| 2231 | L30 dtf.jpg  |   L   | empty |    0.0     | False  |\n",
            "| 2234 | L163 dtf.jpg |   L   | empty |    0.0     | False  |\n",
            "| 2242 | A325 dtf.jpg |   A   | empty |    0.0     | False  |\n",
            "| 2253 | A131 dtf.jpg |   A   | empty |    0.0     | False  |\n",
            "| 2369 | Y167 dtf.jpg |   Y   | empty |    0.0     | False  |\n",
            "| 2371 | Y147 dtf.jpg |   Y   | empty |    0.0     | False  |\n",
            "| 2372 | Y146 dtf.jpg |   Y   | empty |    0.0     | False  |\n",
            "| 2387 | Y144 dtf.jpg |   Y   | empty |    0.0     | False  |\n",
            "| 2390 | Y155 dtf.jpg |   Y   | empty |    0.0     | False  |\n",
            "| 2403 | Y150 dtf.jpg |   Y   | empty |    0.0     | False  |\n",
            "| 2412 | Y69 dtf.jpg  |   Y   | empty |    0.0     | False  |\n",
            "| 2414 | Y63 dtf.jpg  |   Y   | empty |    0.0     | False  |\n",
            "| 2416 | Y152 dtf.jpg |   Y   | empty |    0.0     | False  |\n",
            "| 2420 | Y160 dtf.jpg |   Y   | empty |    0.0     | False  |\n",
            "+------+--------------+-------+-------+------------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "low_conf_df.to_csv(\"prediksi_confidence_dibawah_50.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "ZL6w3hIlR2MN"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "# Menambahkan kolom 'result' untuk mengevaluasi apakah prediksi benar atau salah\n",
        "results_df[\"result\"] = results_df[\"pred\"] == results_df[\"label\"]\n",
        "\n",
        "# Menentukan urutan kelas dari A-Y\n",
        "classes = sorted(results_df[\"label\"].unique())  # Mengurutkan kelas dari A hingga Y\n",
        "\n",
        "# Menghitung precision, recall, dan f1-score untuk masing-masing kelas\n",
        "report = classification_report(\n",
        "    results_df[\"label\"],\n",
        "    results_df[\"pred\"],\n",
        "    labels=classes,  # Menambahkan urutan kelas\n",
        "    zero_division=0\n",
        ")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Menambahkan nilai rata-rata precision, recall, f1-score\n",
        "precision_avg = precision_score(results_df[\"label\"], results_df[\"pred\"], average='macro', zero_division=0)\n",
        "recall_avg = recall_score(results_df[\"label\"], results_df[\"pred\"], average='macro', zero_division=0)\n",
        "f1_avg = f1_score(results_df[\"label\"], results_df[\"pred\"], average='macro', zero_division=0)\n",
        "\n",
        "print(\"\\nAverage Metrics:\")\n",
        "print(f\"Precision (average): {precision_avg:.4f}\")\n",
        "print(f\"Recall (average): {recall_avg:.4f}\")\n",
        "print(f\"F1 Score (average): {f1_avg:.4f}\")\n"
      ],
      "metadata": {
        "id": "oio_ZOrGPioA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3307811b-02e2-45d9-d239-8f279046f82b"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.99      0.96      0.97       161\n",
            "           B       0.98      0.92      0.95       309\n",
            "           C       0.98      0.86      0.92       150\n",
            "           D       0.93      0.82      0.87       152\n",
            "           E       0.99      0.92      0.95       167\n",
            "           F       0.99      0.84      0.91       167\n",
            "           G       0.99      0.81      0.89       162\n",
            "           H       1.00      0.84      0.91       153\n",
            "           I       0.96      0.92      0.94       161\n",
            "           K       0.99      0.81      0.89       158\n",
            "           L       1.00      0.88      0.94       153\n",
            "           M       0.99      0.86      0.92       159\n",
            "           N       0.97      0.88      0.92       157\n",
            "           O       0.97      0.84      0.90       161\n",
            "           P       0.99      0.83      0.90       162\n",
            "           Q       0.96      0.80      0.87       152\n",
            "           R       0.92      0.75      0.83       149\n",
            "           S       0.95      0.86      0.90       160\n",
            "           T       0.89      0.87      0.88       155\n",
            "           U       0.92      0.82      0.87       159\n",
            "           V       0.97      0.84      0.90       162\n",
            "           W       1.00      0.82      0.90       156\n",
            "           X       0.99      0.77      0.86       179\n",
            "           Y       1.00      0.88      0.93       163\n",
            "\n",
            "   micro avg       0.97      0.85      0.91      3967\n",
            "   macro avg       0.97      0.85      0.91      3967\n",
            "weighted avg       0.97      0.85      0.91      3967\n",
            "\n",
            "\n",
            "Average Metrics:\n",
            "Precision (average): 0.8963\n",
            "Recall (average): 0.7846\n",
            "F1 Score (average): 0.8360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengelompokkan hasil prediksi\n",
        "results_df[\"result\"] = np.where(\n",
        "    results_df.pred == results_df.label,\n",
        "    \"correct\",\n",
        "    np.where(results_df.pred.isin([\"empty\", \"n/a\"]), \"not found\", \"incorrect\")\n",
        ")\n",
        "\n",
        "# Mengatur urutan kategori untuk kolom 'result'\n",
        "results_df[\"result\"] = pd.Categorical(\n",
        "    results_df[\"result\"],\n",
        "    categories=[\"not found\", \"incorrect\", \"correct\"],\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "# Membuat urutan kategori dari A hingga Y\n",
        "label_order = sorted(results_df[\"label\"].unique())  # Menyortir label secara alfabetis\n",
        "\n",
        "# Mengubah kolom 'label' menjadi kategori dengan urutan yang sudah ditentukan\n",
        "results_df[\"label\"] = pd.Categorical(results_df[\"label\"], categories=label_order, ordered=True)\n",
        "\n",
        "# Atur gaya dan tema seaborn\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "sns.set_palette(\"pastel\")\n",
        "\n",
        "# Membuat histogram dengan seaborn\n",
        "plt.figure(figsize=(12, 8))\n",
        "ax = sns.histplot(\n",
        "    data=results_df,\n",
        "    x=\"label\",\n",
        "    hue=\"result\",\n",
        "    multiple=\"stack\",\n",
        "    stat=\"count\",\n",
        "    palette={\"correct\": \"mediumseagreen\", \"incorrect\": \"coral\", \"not found\": \"gray\"},  # Urutan warna sesuai kategori\n",
        "    legend=True\n",
        ")\n",
        "\n",
        "# Menambahkan judul dan label\n",
        "plt.title(\"Prediction Results by Label\", fontsize=16)\n",
        "plt.xlabel(\"Labels\", fontsize=14)\n",
        "plt.ylabel(\"Count\", fontsize=14)\n",
        "\n",
        "# Menampilkan legenda secara eksplisit\n",
        "plt.legend(\n",
        "    title=\"Result\",\n",
        "    title_fontsize=14,\n",
        "    fontsize=12,\n",
        "    loc=\"upper right\",\n",
        "    labels=[\"Correct\", \"Incorrect\", \"Not Found\"]  # Disesuaikan dengan urutan kategori\n",
        ")\n",
        "\n",
        "# Menyimpan grafik\n",
        "plt.savefig(\"prediction_results_with_ordered_labels.png\", bbox_inches=\"tight\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tbyrKa52mzuv"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.query(\"result == 'not found'\").groupby(\n",
        "    \"label\"\n",
        ").pred.value_counts().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "JMKD_8ubopRJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "daddc3ff-10b5-4d21-c867-3190516b4105"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-78-3367209435.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  results_df.query(\"result == 'not found'\").groupby(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label  pred \n",
              "H      empty    17\n",
              "W      empty    17\n",
              "B      empty    15\n",
              "X      empty    14\n",
              "P      empty    13\n",
              "Q      empty    12\n",
              "R      empty    11\n",
              "Q      n/a      11\n",
              "G      empty    11\n",
              "K      empty    10\n",
              "S      empty    10\n",
              "Y      empty    10\n",
              "V      empty    10\n",
              "L      empty     8\n",
              "N      empty     8\n",
              "F      empty     8\n",
              "C      empty     8\n",
              "X      n/a       8\n",
              "K      n/a       7\n",
              "R      n/a       7\n",
              "D      n/a       7\n",
              "I      empty     6\n",
              "G      n/a       6\n",
              "U      n/a       6\n",
              "       empty     6\n",
              "E      empty     6\n",
              "M      empty     5\n",
              "V      n/a       4\n",
              "N      n/a       4\n",
              "O      n/a       4\n",
              "T      n/a       4\n",
              "D      empty     4\n",
              "B      n/a       3\n",
              "I      n/a       3\n",
              "A      empty     2\n",
              "P      n/a       2\n",
              "H      n/a       2\n",
              "E      n/a       2\n",
              "C      n/a       2\n",
              "S      n/a       1\n",
              "T      empty     1\n",
              "A      n/a       1\n",
              "M      n/a       1\n",
              "W      n/a       1\n",
              "F      n/a       1\n",
              "Y      n/a       1\n",
              "O      empty     0\n",
              "L      n/a       0\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>H</th>\n",
              "      <th>empty</th>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>W</th>\n",
              "      <th>empty</th>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <th>empty</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X</th>\n",
              "      <th>empty</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P</th>\n",
              "      <th>empty</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q</th>\n",
              "      <th>empty</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R</th>\n",
              "      <th>empty</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q</th>\n",
              "      <th>n/a</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>G</th>\n",
              "      <th>empty</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K</th>\n",
              "      <th>empty</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S</th>\n",
              "      <th>empty</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Y</th>\n",
              "      <th>empty</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V</th>\n",
              "      <th>empty</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L</th>\n",
              "      <th>empty</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>N</th>\n",
              "      <th>empty</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F</th>\n",
              "      <th>empty</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C</th>\n",
              "      <th>empty</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X</th>\n",
              "      <th>n/a</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K</th>\n",
              "      <th>n/a</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R</th>\n",
              "      <th>n/a</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D</th>\n",
              "      <th>n/a</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I</th>\n",
              "      <th>empty</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>G</th>\n",
              "      <th>n/a</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">U</th>\n",
              "      <th>n/a</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>empty</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E</th>\n",
              "      <th>empty</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>M</th>\n",
              "      <th>empty</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V</th>\n",
              "      <th>n/a</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>N</th>\n",
              "      <th>n/a</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <th>n/a</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T</th>\n",
              "      <th>n/a</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D</th>\n",
              "      <th>empty</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <th>n/a</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I</th>\n",
              "      <th>n/a</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A</th>\n",
              "      <th>empty</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P</th>\n",
              "      <th>n/a</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H</th>\n",
              "      <th>n/a</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E</th>\n",
              "      <th>n/a</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C</th>\n",
              "      <th>n/a</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S</th>\n",
              "      <th>n/a</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T</th>\n",
              "      <th>empty</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A</th>\n",
              "      <th>n/a</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>M</th>\n",
              "      <th>n/a</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>W</th>\n",
              "      <th>n/a</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F</th>\n",
              "      <th>n/a</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Y</th>\n",
              "      <th>n/a</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <th>empty</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L</th>\n",
              "      <th>n/a</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_data.gen_tf_dataset(batch_size=train_data.size)\n",
        "xy = train_ds.take(1).get_single_element()\n",
        "\n",
        "embeddings, classes_onehot = xy[0].numpy(), xy[1].numpy()  # type: ignore\n",
        "class_indices = np.argmax(classes_onehot, axis=1)\n",
        "\n",
        "print(embeddings.shape, class_indices.shape)\n",
        "# -> (1861, 128) (1861,)"
      ],
      "metadata": {
        "id": "8FgDD3moo0FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "import pandas as pd\n",
        "\n",
        "# Ambil label asli dan nama file\n",
        "true_labels = [f.parent.name for f in train_files]\n",
        "file_names = [f.name for f in train_files]\n",
        "\n",
        "# List kosong untuk hasil prediksi\n",
        "pred_labels = []\n",
        "confidences = []\n",
        "\n",
        "# Proses prediksi\n",
        "for f in train_files:\n",
        "    image = mp.Image.create_from_file(str(f))\n",
        "    result = recognizer.recognize(image)\n",
        "\n",
        "    if result.gestures and result.gestures[0]:\n",
        "        top_pred = result.gestures[0][0]\n",
        "        pred_labels.append(top_pred.category_name)\n",
        "        confidences.append(top_pred.score)\n",
        "    else:\n",
        "        pred_labels.append(\"empty\")\n",
        "        confidences.append(0.0)\n",
        "\n",
        "# Buat DataFrame lengkap\n",
        "results_df = pd.DataFrame({\n",
        "    \"file\": file_names,\n",
        "    \"label\": true_labels,\n",
        "    \"pred\": pred_labels,\n",
        "    \"confidence\": confidences\n",
        "})\n",
        "\n",
        "# Tandai benar/salah/tidak ditemukan\n",
        "import numpy as np\n",
        "\n",
        "results_df[\"result\"] = np.where(\n",
        "    results_df.pred == results_df.label,\n",
        "    \"correct\",\n",
        "    np.where(results_df.pred.isin([\"empty\", \"n/a\"]), \"not found\", \"incorrect\")\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "0r_2pJtH9kBD",
        "outputId": "1c04d75d-428d-48ef-f0e2-7c95ae9d0218"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Task runner is currently not running.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-81-1078843271.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgestures\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgestures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mediapipe/tasks/python/vision/gesture_recognizer.py\u001b[0m in \u001b[0;36mrecognize\u001b[0;34m(self, image, image_processing_options)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mimage_processing_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_allowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     )\n\u001b[0;32m--> 377\u001b[0;31m     output_packets = self._process_image_data({\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0m_IMAGE_IN_STREAM_NAME\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpacket_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         _NORM_RECT_STREAM_NAME: packet_creator.create_proto(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mediapipe/tasks/python/vision/core/base_vision_task_api.py\u001b[0m in \u001b[0;36m_process_image_data\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     93\u001b[0m           \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       )\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   def _process_video_data(\n",
            "\u001b[0;31mValueError\u001b[0m: Task runner is currently not running."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.manifold\n",
        "\n",
        "tsne = sklearn.manifold.TSNE()\n",
        "emb = tsne.fit_transform(embeddings)\n"
      ],
      "metadata": {
        "id": "G8HYUd1VQc1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "embdf = pd.DataFrame(emb, columns=[\"X1\", \"X2\"]).assign(label=class_indices)\n",
        "sns.scatterplot(\n",
        "    data=embdf, x=\"X1\", y=\"X2\", hue=\"label\", palette=\"Spectral\", legend=False\n",
        ")\n",
        "for i, c in enumerate(train_data.label_names):\n",
        "    if np.all(class_indices != i):\n",
        "        continue\n",
        "    center = emb[class_indices == i].mean(axis=0)\n",
        "    plt.annotate(c, center, center - 6)\n",
        "    plt.savefig(\"result.png\")\n"
      ],
      "metadata": {
        "id": "x_G9ankgQtiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "results_df[\"result\"] = np.where(\n",
        "    results_df.pred == results_df.label,\n",
        "    \"correct\",\n",
        "    np.where(results_df.pred.isin([\"n/a\", \"empty\"]), \"not found\", \"incorrect\"),\n",
        ")\n",
        "print(results_df.result.value_counts(normalize=True))\n",
        "sns.histplot(\n",
        "    data=results_df, x=\"label\", hue=\"result\", multiple=\"stack\", stat=\"count\"\n",
        ")"
      ],
      "metadata": {
        "id": "nNDm-tkhShMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "embdf = pd.DataFrame(emb, columns=[\"X1\", \"X2\"]).assign(label=class_indices)\n",
        "sns.scatterplot(\n",
        "    data=embdf, x=\"X1\", y=\"X2\", hue=\"label\", palette=\"Spectral\", legend=False\n",
        ")\n",
        "for i, c in enumerate(train_data.label_names):\n",
        "    if np.all(class_indices != i):\n",
        "        continue\n",
        "    center = emb[class_indices == i].mean(axis=0)\n",
        "    plt.annotate(c, center, center - 6)\n",
        "    plt.savefig(\"result.png\")\n"
      ],
      "metadata": {
        "id": "yEBdk--nS46v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}